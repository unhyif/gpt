{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 355\n",
      "\tPrompt Tokens: 15\n",
      "\tCompletion Tokens: 340\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0007025\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler, get_openai_callback\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "set_llm_cache(SQLiteCache())\n",
    "\n",
    "chat = ChatOpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    chat.predict(\"What's the recipe for sangria?\")\n",
    "    print(usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Svelte has several advantages over other JavaScript frameworks and libraries:\n",
      "\n",
      "1. Performance: Svelte compiles the code at build time, which means that the resulting bundle sent to the browser is highly optimized and requires minimal runtime overhead. This results in faster loading times and better overall performance compared to frameworks that need to execute code at runtime.\n",
      "\n",
      "2. Small bundle size: Svelte generates highly efficient and minimal JavaScript code, resulting in smaller bundle sizes. This means faster downloads, reduced bandwidth usage, and improved user experience, especially on mobile devices and in areas with slower internet connections.\n",
      "\n",
      "3. Easy learning curve: Svelte has a simple and intuitive syntax that is easy to learn and understand. It does not have a steep learning curve like some other frameworks, making it an attractive option for developers, particularly those who are new to front-end development.\n",
      "\n",
      "4. Reactive programming: Svelte uses a reactive programming paradigm, where changes in state automatically update the DOM without the need for additional code. This enables developers to write less code, resulting in faster development and easier maintenance.\n",
      "\n",
      "5. Framework-agnostic: Svelte is not tied to any specific framework or library, allowing developers to easily integrate it into existing projects or use it in combination with other frameworks if desired. This flexibility makes it a versatile choice for a wide range of applications.\n",
      "\n",
      "6. Strong developer community: Despite being a relatively new framework, Svelte has gained a strong and active developer community. This means that there is a growing number of resources, tutorials, and libraries available, making it easier for developers to get support and find solutions to their problems.\n",
      "\n",
      "Overall, Svelte offers a combination of performance, simplicity, and flexibility that makes it an attractive choice for building modern web applications.안녕하세요! 저는 한국어로 답변하는 AI 어시스턴트입니다. Next.js의 장점은 다음과 같습니다:\n",
      "\n",
      "1. 서버 사이드 렌더링 (SSR): Next.js는 서버 사이드 렌더링을 기본적으로 지원하여 초기 페이지 로딩 속도를 개선하고 SEO에 뛰어난 성능을 제공합니다.\n",
      "\n",
      "2. 정적 사이트 생성 (SSG): Next.js는 정적 사이트 생성을 지원하여 사전 렌더링을 통해 성능을 향상시킵니다. 정적 사이트 생성은 동적인 데이터가 자주 변경되지 않는 경우에 유용합니다.\n",
      "\n",
      "3. 자동 코드 분할 (Automatic Code Splitting): Next.js는 페이지 단위로 자동으로 코드를 분할하여 필요한 부분만을 로드하므로 초기 페이지 로딩 속도가 향상됩니다.\n",
      "\n",
      "4. 간편한 라우팅: Next.js는 파일 시스템 기반의 라우팅을 제공하여 라우팅 설정이 간단합니다. 파일 이름에 따라 페이지 경로가 자동으로 생성되므로 개발자가 별도의 라우팅 설정을 할 필요가 없습니다.\n",
      "\n",
      "5. 풍부한 생태계: Next.js는 프론트엔드 개발에 필요한 다양한 기능과 라이브러리를 포함한 풍부한 생태계를 제공합니다. 예를 들어, CSS-in-JS 라이브러리인 Styled Components나 상태 관리 라이브러리인 Redux와의 통합이 간편합니다.\n",
      "\n",
      "저는 AI 어시스턴트이므로 개인 이름은 없습니다. 어떤 점을 도움 드릴까요?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='안녕하세요! 저는 한국어로 답변하는 AI 어시스턴트입니다. Next.js의 장점은 다음과 같습니다:\\n\\n1. 서버 사이드 렌더링 (SSR): Next.js는 서버 사이드 렌더링을 기본적으로 지원하여 초기 페이지 로딩 속도를 개선하고 SEO에 뛰어난 성능을 제공합니다.\\n\\n2. 정적 사이트 생성 (SSG): Next.js는 정적 사이트 생성을 지원하여 사전 렌더링을 통해 성능을 향상시킵니다. 정적 사이트 생성은 동적인 데이터가 자주 변경되지 않는 경우에 유용합니다.\\n\\n3. 자동 코드 분할 (Automatic Code Splitting): Next.js는 페이지 단위로 자동으로 코드를 분할하여 필요한 부분만을 로드하므로 초기 페이지 로딩 속도가 향상됩니다.\\n\\n4. 간편한 라우팅: Next.js는 파일 시스템 기반의 라우팅을 제공하여 라우팅 설정이 간단합니다. 파일 이름에 따라 페이지 경로가 자동으로 생성되므로 개발자가 별도의 라우팅 설정을 할 필요가 없습니다.\\n\\n5. 풍부한 생태계: Next.js는 프론트엔드 개발에 필요한 다양한 기능과 라이브러리를 포함한 풍부한 생태계를 제공합니다. 예를 들어, CSS-in-JS 라이브러리인 Styled Components나 상태 관리 라이브러리인 Redux와의 통합이 간편합니다.\\n\\n저는 AI 어시스턴트이므로 개인 이름은 없습니다. 어떤 점을 도움 드릴까요?')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"What is the advantage of {frontend_stack}?\"\n",
    ").format(frontend_stack=\"Svelte\")\n",
    "chat.predict(prompt)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a frontend expert. Also, you only reply in {language}\"),\n",
    "        (\"ai\", \"{tone}\"),\n",
    "        (\"human\", \"What is the advantage of {frontend_stack}? Also, what's your name?\"),\n",
    "    ]\n",
    ").format_messages(language=\"Korean\", tone=\"안녕하세요!\", frontend_stack=\"Next.js\")\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', 'how', 'are', 'you']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output Parser\n",
    "\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text):\n",
    "        return list(map(str.strip, text.split(\",\")))\n",
    "\n",
    "\n",
    "parser = CommaOutputParser()\n",
    "parser.parse(\" Hello, how,are,you \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html, css, javascript, responsive design, user experience"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['html', 'css', 'javascript', 'responsive design', 'user experience']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Langchain Expression Language\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anything else\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "chain = prompt | chat | parser\n",
    "chain.invoke(\n",
    "    {\"max_items\": 5, \"question\": \"Interesting things about frontend development\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is full of vibrant flavors and aromatic spices. Let's start with a classic Indian dish called Butter Chicken. Here's a simple and delicious recipe for you:\n",
      "\n",
      "Ingredients:\n",
      "- 500g boneless chicken, cut into bite-sized pieces\n",
      "- 2 tablespoons butter\n",
      "- 1 large onion, finely chopped\n",
      "- 2 cloves of garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 2 teaspoons garam masala\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon chili powder (adjust to your spice preference)\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup heavy cream\n",
      "- Salt to taste\n",
      "- Fresh cilantro leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Heat the butter in a large pan over medium heat. Add the chopped onions and sauté until golden brown.\n",
      "2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\n",
      "3. In a small bowl, mix the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute to release the flavors.\n",
      "4. Add the chicken pieces to the pan and cook until they are lightly browned on all sides.\n",
      "5. Pour in the tomato puree and season with salt. Mix well and let the sauce simmer for about 15-20 minutes, or until the chicken is cooked through.\n",
      "6. Stir in the heavy cream and let it simmer for an additional 5 minutes to thicken the sauce.\n",
      "7. Garnish with fresh cilantro leaves and serve hot with steamed rice or naan bread.\n",
      "\n",
      "Enjoy your homemade Butter Chicken! Feel free to adjust the spices according to your taste preferences.Great choice! Butter Chicken is a delicious and popular Indian dish. To make it vegetarian, we'll need to replace the chicken with a suitable alternative. Here's a vegetarian version of the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 500g paneer (Indian cottage cheese), cut into bite-sized pieces\n",
      "- 2 tablespoons butter (or vegan butter for a vegan version)\n",
      "- 1 large onion, finely chopped\n",
      "- 2 cloves of garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 2 teaspoons garam masala\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon chili powder (adjust to your spice preference)\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup heavy cream (or coconut cream for a vegan version)\n",
      "- Salt to taste\n",
      "- Fresh cilantro leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Heat the butter in a large pan over medium heat. Add the chopped onions and sauté until golden brown.\n",
      "2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\n",
      "3. In a small bowl, mix the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute to release the flavors.\n",
      "4. Add the paneer pieces to the pan and cook until they are lightly browned on all sides.\n",
      "5. Pour in the tomato puree and season with salt. Mix well and let the sauce simmer for about 15-20 minutes, allowing the flavors to meld together.\n",
      "6. Stir in the heavy cream (or coconut cream) and let it simmer for an additional 5 minutes to thicken the sauce.\n",
      "7. Garnish with fresh cilantro leaves and serve hot with steamed rice or naan bread.\n",
      "\n",
      "Enjoy your vegetarian Butter Paneer! It's a flavorful alternative to the traditional Chicken Butter."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Great choice! Butter Chicken is a delicious and popular Indian dish. To make it vegetarian, we'll need to replace the chicken with a suitable alternative. Here's a vegetarian version of the recipe:\\n\\nIngredients:\\n- 500g paneer (Indian cottage cheese), cut into bite-sized pieces\\n- 2 tablespoons butter (or vegan butter for a vegan version)\\n- 1 large onion, finely chopped\\n- 2 cloves of garlic, minced\\n- 1-inch piece of ginger, grated\\n- 2 teaspoons garam masala\\n- 1 teaspoon turmeric powder\\n- 1 teaspoon chili powder (adjust to your spice preference)\\n- 1 cup tomato puree\\n- 1/2 cup heavy cream (or coconut cream for a vegan version)\\n- Salt to taste\\n- Fresh cilantro leaves for garnish\\n\\nInstructions:\\n1. Heat the butter in a large pan over medium heat. Add the chopped onions and sauté until golden brown.\\n2. Add the minced garlic and grated ginger to the pan. Cook for another minute until fragrant.\\n3. In a small bowl, mix the garam masala, turmeric powder, and chili powder. Add this spice mixture to the pan and cook for a minute to release the flavors.\\n4. Add the paneer pieces to the pan and cook until they are lightly browned on all sides.\\n5. Pour in the tomato puree and season with salt. Mix well and let the sauce simmer for about 15-20 minutes, allowing the flavors to meld together.\\n6. Stir in the heavy cream (or coconut cream) and let it simmer for an additional 5 minutes to thicken the sauce.\\n7. Garnish with fresh cilantro leaves and serve hot with steamed rice or naan bread.\\n\\nEnjoy your vegetarian Butter Paneer! It's a flavorful alternative to the traditional Chicken Butter.\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chaining Chains\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a world-class international chef. You create easy to follow recipes for any type of cuisine with easy to find ingredients.\",\n",
    "        ),\n",
    "        (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "    ]\n",
    ")\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a vegetarian chef specialized on making traditional recipes vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to recipe it.\",\n",
    "        ),\n",
    "        (\"human\", \"{recipe}\"),\n",
    "    ]\n",
    ")\n",
    "veg_chef_chain = veg_chef_prompt | chat\n",
    "\n",
    "chain = {\"recipe\": chef_chain} | veg_chef_chain\n",
    "chain.invoke({\"cuisine\": \"indian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "Here is what I know about Sweden:\n",
      "Capital: Stockholm\n",
      "Language: Swedish\n",
      "Food: Meatballs, herring, and lingonberries\n",
      "Currency: Swedish Krona\n",
      "Famous for: ABBA, IKEA, Volvo, and beautiful natural landscapes such as the Northern Lights and the archipelago."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nHere is what I know about Sweden:\\nCapital: Stockholm\\nLanguage: Swedish\\nFood: Meatballs, herring, and lingonberries\\nCurrency: Swedish Krona\\nFamous for: ABBA, IKEA, Volvo, and beautiful natural landscapes such as the Northern Lights and the archipelago.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotPromptTemplate, Example Selector\n",
    "\n",
    "from langchain.prompts.few_shot import (\n",
    "    FewShotPromptTemplate,\n",
    "    FewShotChatMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "template = \"Human: {question}\\nAI: {answer}\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "selector = RandomExampleSelector(examples=examples)\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=prompt,\n",
    "    example_selector=selector,\n",
    "    suffix=\"Human: {question}\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"question\": \"I wonder about Sweden\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I know this:\n",
      "Capital: Stockholm\n",
      "Language: Swedish\n",
      "Food: Meatballs and Herring\n",
      "Currency: Swedish Krona"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='I know this:\\nCapital: Stockholm\\nLanguage: Swedish\\nFood: Meatballs and Herring\\nCurrency: Swedish Krona')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"human\", \"What do you know about {country}?\"), (\"ai\", \"{answer}\")]\n",
    ")\n",
    "prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert, you give short answers\"),\n",
    "        prompt,\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"country\": \"Sweden\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of South Korea is Seoul."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='The capital of South Korea is Seoul.')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Serialization\n",
    "\n",
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"./prompt.yaml\")\n",
    "chain = prompt | chat\n",
    "chain.invoke({\"country\": \"South Korea\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrgh, me heartie! Me favorite food be none other than a hearty plate o' seafood! I can't resist the taste o' fresh fish, lobster, and shrimp straight from the depths o' the sea. And don't ye forget about me trusty bottle o' rum to wash it all down! Arrrr!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrgh, me heartie! Me favorite food be none other than a hearty plate o' seafood! I can't resist the taste o' fresh fish, lobster, and shrimp straight from the depths o' the sea. And don't ye forget about me trusty bottle o' rum to wash it all down! Arrrr!\")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Composition\n",
    "\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "full_prompt = PipelinePromptTemplate(final_prompt=final, pipeline_prompts=prompts)\n",
    "\n",
    "chain = full_prompt | chat\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jihyun/Desktop/gpt/env/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/jihyun/Desktop/gpt/env/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am an AI language model developed by OpenAI. I am designed to assist with various tasks and provide information on a wide range of topics. How can I assist you today?'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Serialization\n",
    "\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "chat = OpenAI(temperature=0.1, max_tokens=450, model=\"gpt-3.5-turbo-16k\")\n",
    "chat.save(\"model.json\")\n",
    "\n",
    "chat = load_llm(\"model.json\")\n",
    "chat.predict(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
